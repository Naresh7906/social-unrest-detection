{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import *\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Conv1D, MaxPooling1D, Bidirectional, LSTM, Dense, Dropout\n",
    "from keras.metrics import Precision, Recall\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "import keras.backend as K\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_text</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>allnews2nite The international Society should...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rosslynpark have already been through a rigor...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Join the race to curb the silence on breast ca...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Family    I need your attention please we are ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PradeepgyawaliK communist ko suvkamana yeti s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6182</th>\n",
       "      <td>I wanna throw my feelings in the trash</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6183</th>\n",
       "      <td>Current love situation   I strike to burn and ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6184</th>\n",
       "      <td>Why are we here  Intelligence community should...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6185</th>\n",
       "      <td>Business is time or nothing something that th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6186</th>\n",
       "      <td>Robstencry Not like Hantol s to be honest  An...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6187 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             clean_text  category\n",
       "0      allnews2nite The international Society should...         1\n",
       "1      rosslynpark have already been through a rigor...         1\n",
       "2     Join the race to curb the silence on breast ca...         0\n",
       "3     Family    I need your attention please we are ...         0\n",
       "4      PradeepgyawaliK communist ko suvkamana yeti s...         0\n",
       "...                                                 ...       ...\n",
       "6182            I wanna throw my feelings in the trash          0\n",
       "6183  Current love situation   I strike to burn and ...         0\n",
       "6184  Why are we here  Intelligence community should...         1\n",
       "6185   Business is time or nothing something that th...         0\n",
       "6186   Robstencry Not like Hantol s to be honest  An...         0\n",
       "\n",
       "[6187 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('unrest_2.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()\n",
    "df.dropna(axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_text</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>allnews2nite The international Society should...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rosslynpark have already been through a rigor...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Join the race to curb the silence on breast ca...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Family    I need your attention please we are ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PradeepgyawaliK communist ko suvkamana yeti s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6182</th>\n",
       "      <td>I wanna throw my feelings in the trash</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6183</th>\n",
       "      <td>Current love situation   I strike to burn and ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6184</th>\n",
       "      <td>Why are we here  Intelligence community should...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6185</th>\n",
       "      <td>Business is time or nothing something that th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6186</th>\n",
       "      <td>Robstencry Not like Hantol s to be honest  An...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6187 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             clean_text  category\n",
       "0      allnews2nite The international Society should...         1\n",
       "1      rosslynpark have already been through a rigor...         1\n",
       "2     Join the race to curb the silence on breast ca...         0\n",
       "3     Family    I need your attention please we are ...         0\n",
       "4      PradeepgyawaliK communist ko suvkamana yeti s...         0\n",
       "...                                                 ...       ...\n",
       "6182            I wanna throw my feelings in the trash          0\n",
       "6183  Current love situation   I strike to burn and ...         0\n",
       "6184  Why are we here  Intelligence community should...         1\n",
       "6185   Business is time or nothing something that th...         0\n",
       "6186   Robstencry Not like Hantol s to be honest  An...         0\n",
       "\n",
       "[6187 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Original tweet ->  allnews2nite The international Society should listen to the Libyan people voice by all means   listening and talking to the Armed groups looks like having dialogue with Mafias and gangs   those do not care about concept of building respected  civilized state \n",
      "\n",
      "Processed tweet -> ['allnews2nit', 'intern', 'societi', 'listen', 'libyan', 'peopl', 'voic', 'mean', 'listen', 'talk', 'arm', 'group', 'look', 'like', 'dialogu', 'mafia', 'gang', 'care', 'concept', 'build', 'respect', 'civil', 'state']\n"
     ]
    }
   ],
   "source": [
    "def tweet_to_words(tweet):\n",
    "    text = tweet.lower()\n",
    "    text = re.sub(r\"[^a-zA-Z0-9]\", \" \", text)\n",
    "    words = text.split()\n",
    "    words = [w for w in words if w not in stopwords.words(\"english\")]\n",
    "    words = [PorterStemmer().stem(w) for w in words]\n",
    "    return words\n",
    "\n",
    "print(\"\\nOriginal tweet ->\", df['clean_text'][0])\n",
    "print(\"\\nProcessed tweet ->\", tweet_to_words(df['clean_text'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = list(map(tweet_to_words, df['clean_text'][:10000]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = df['category'][:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pd.get_dummies(df['category'][:10000])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary_size = 5000\n",
    "count_vector = CountVectorizer(max_features=vocabulary_size,\n",
    "                                preprocessor=lambda x: x,\n",
    "                               tokenizer=lambda x: x) \n",
    "X_train = count_vector.fit_transform(X_train).toarray()\n",
    "X_test = count_vector.transform(X_test).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Tokenization & Padding \n",
      "  allnews2nite The international Society should listen to the Libyan people voice by all means   listening and talking to the Armed groups looks like having dialogue with Mafias and gangs   those do not care about concept of building respected  civilized state \n",
      "After Tokenization & Padding \n",
      " [4689    1  197  435   89 1190    3    1  806   38 1191   28   37  376\n",
      " 2125    8  762    3    1   61  260  807   75  478  547   21 4690    8\n",
      " 4691  127   53   25  339   58 2126    5  808 2127 4692  169    0    0\n",
      "    0    0    0    0    0    0    0    0]\n"
     ]
    }
   ],
   "source": [
    "max_words = 5000\n",
    "max_len=50\n",
    "\n",
    "def tokenize_pad_sequences(text):\n",
    "    tokenizer = Tokenizer(num_words=max_words, lower=True, split=' ')\n",
    "    tokenizer.fit_on_texts(text)\n",
    "    X = tokenizer.texts_to_sequences(text)\n",
    "    X = pad_sequences(X, padding='post', maxlen=max_len)\n",
    "    return X, tokenizer\n",
    "\n",
    "print('Before Tokenization & Padding \\n', df['clean_text'][0])\n",
    "X, tokenizer = tokenize_pad_sequences(df['clean_text'])\n",
    "print('After Tokenization & Padding \\n', X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('tokenizer.pickle', 'wb') as handle:\n",
    "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open('tokenizer.pickle', 'rb') as handle:\n",
    "    tokenizer = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Set -> (4949, 50) (4949, 2)\n",
      "Test Set -> (1238, 50) (1238, 2)\n"
     ]
    }
   ],
   "source": [
    "y = pd.get_dummies(df['category'])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "print('Train Set ->', X_train.shape, y_train.shape)\n",
    "print('Test Set ->', X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_score(precision, recall):\n",
    "    \n",
    "    f1_val = 2*(precision*recall)/(precision+recall+K.epsilon())\n",
    "    return f1_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\python\\lib\\site-packages\\keras\\optimizer_v2\\gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\NARESH\\AppData\\Local\\Temp/ipykernel_25520/2249872368.py:13: The name tf.keras.layers.CuDNNLSTM is deprecated. Please use tf.compat.v1.keras.layers.CuDNNLSTM instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 5000\n",
    "embedding_size = 32\n",
    "epochs=20\n",
    "learning_rate = 0.1\n",
    "decay_rate = learning_rate / epochs\n",
    "momentum = 0.8\n",
    "\n",
    "sgd = SGD(lr=learning_rate, momentum=momentum, decay=decay_rate, nesterov=False)\n",
    "model= Sequential()\n",
    "model.add(Embedding(vocab_size, embedding_size, input_length=max_len))\n",
    "model.add(Conv1D(filters=32, kernel_size=3, padding='same', activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Bidirectional(tf.compat.v1.keras.layers.CuDNNLSTM(32)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 50, 32)            160000    \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 50, 32)            3104      \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 25, 32)           0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 64)               16896     \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 64)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 180,130\n",
      "Trainable params: 180,130\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "78/78 [==============================] - 3s 20ms/step - loss: 0.2340 - accuracy: 0.8763 - precision_1: 0.8763 - recall_1: 0.8763 - val_loss: 0.9933 - val_accuracy: 0.7423 - val_precision_1: 0.7423 - val_recall_1: 0.7423\n",
      "Epoch 2/30\n",
      "78/78 [==============================] - 1s 14ms/step - loss: 0.2253 - accuracy: 0.8776 - precision_1: 0.8776 - recall_1: 0.8776 - val_loss: 0.9791 - val_accuracy: 0.7456 - val_precision_1: 0.7456 - val_recall_1: 0.7456\n",
      "Epoch 3/30\n",
      "78/78 [==============================] - 1s 14ms/step - loss: 0.2183 - accuracy: 0.8778 - precision_1: 0.8778 - recall_1: 0.8778 - val_loss: 0.9438 - val_accuracy: 0.7399 - val_precision_1: 0.7399 - val_recall_1: 0.7399\n",
      "Epoch 4/30\n",
      "78/78 [==============================] - 1s 14ms/step - loss: 0.2138 - accuracy: 0.8780 - precision_1: 0.8780 - recall_1: 0.8780 - val_loss: 0.9638 - val_accuracy: 0.7391 - val_precision_1: 0.7391 - val_recall_1: 0.7391\n",
      "Epoch 5/30\n",
      "78/78 [==============================] - 1s 13ms/step - loss: 0.2133 - accuracy: 0.8790 - precision_1: 0.8790 - recall_1: 0.8790 - val_loss: 0.9572 - val_accuracy: 0.7391 - val_precision_1: 0.7391 - val_recall_1: 0.7391\n",
      "Epoch 6/30\n",
      "78/78 [==============================] - 1s 14ms/step - loss: 0.2147 - accuracy: 0.8767 - precision_1: 0.8767 - recall_1: 0.8767 - val_loss: 0.9741 - val_accuracy: 0.7399 - val_precision_1: 0.7399 - val_recall_1: 0.7399\n",
      "Epoch 7/30\n",
      "78/78 [==============================] - 1s 13ms/step - loss: 0.2104 - accuracy: 0.8745 - precision_1: 0.8745 - recall_1: 0.8745 - val_loss: 0.9733 - val_accuracy: 0.7431 - val_precision_1: 0.7431 - val_recall_1: 0.7431\n",
      "Epoch 8/30\n",
      "78/78 [==============================] - 1s 14ms/step - loss: 0.2074 - accuracy: 0.8828 - precision_1: 0.8828 - recall_1: 0.8828 - val_loss: 0.9667 - val_accuracy: 0.7407 - val_precision_1: 0.7407 - val_recall_1: 0.7407\n",
      "Epoch 9/30\n",
      "78/78 [==============================] - 1s 14ms/step - loss: 0.2078 - accuracy: 0.8802 - precision_1: 0.8802 - recall_1: 0.8802 - val_loss: 0.9730 - val_accuracy: 0.7375 - val_precision_1: 0.7375 - val_recall_1: 0.7375\n",
      "Epoch 10/30\n",
      "78/78 [==============================] - 1s 14ms/step - loss: 0.2064 - accuracy: 0.8782 - precision_1: 0.8782 - recall_1: 0.8782 - val_loss: 0.9919 - val_accuracy: 0.7375 - val_precision_1: 0.7375 - val_recall_1: 0.7375\n",
      "Epoch 11/30\n",
      "78/78 [==============================] - 1s 13ms/step - loss: 0.2107 - accuracy: 0.8802 - precision_1: 0.8802 - recall_1: 0.8802 - val_loss: 0.9753 - val_accuracy: 0.7375 - val_precision_1: 0.7375 - val_recall_1: 0.7375\n",
      "Epoch 12/30\n",
      "78/78 [==============================] - 1s 14ms/step - loss: 0.2050 - accuracy: 0.8816 - precision_1: 0.8816 - recall_1: 0.8816 - val_loss: 0.9896 - val_accuracy: 0.7439 - val_precision_1: 0.7439 - val_recall_1: 0.7439\n",
      "Epoch 13/30\n",
      "78/78 [==============================] - 1s 16ms/step - loss: 0.2010 - accuracy: 0.8826 - precision_1: 0.8826 - recall_1: 0.8826 - val_loss: 0.9733 - val_accuracy: 0.7415 - val_precision_1: 0.7415 - val_recall_1: 0.7415\n",
      "Epoch 14/30\n",
      "78/78 [==============================] - 1s 14ms/step - loss: 0.2019 - accuracy: 0.8814 - precision_1: 0.8814 - recall_1: 0.8814 - val_loss: 1.0030 - val_accuracy: 0.7407 - val_precision_1: 0.7407 - val_recall_1: 0.7407\n",
      "Epoch 15/30\n",
      "78/78 [==============================] - 1s 14ms/step - loss: 0.2080 - accuracy: 0.8735 - precision_1: 0.8735 - recall_1: 0.8735 - val_loss: 0.9969 - val_accuracy: 0.7399 - val_precision_1: 0.7399 - val_recall_1: 0.7399\n",
      "Epoch 16/30\n",
      "78/78 [==============================] - 1s 14ms/step - loss: 0.2014 - accuracy: 0.8763 - precision_1: 0.8763 - recall_1: 0.8763 - val_loss: 0.9786 - val_accuracy: 0.7375 - val_precision_1: 0.7375 - val_recall_1: 0.7375\n",
      "Epoch 17/30\n",
      "78/78 [==============================] - 1s 14ms/step - loss: 0.1990 - accuracy: 0.8834 - precision_1: 0.8834 - recall_1: 0.8834 - val_loss: 0.9892 - val_accuracy: 0.7407 - val_precision_1: 0.7407 - val_recall_1: 0.7407\n",
      "Epoch 18/30\n",
      "78/78 [==============================] - 1s 16ms/step - loss: 0.1969 - accuracy: 0.8804 - precision_1: 0.8804 - recall_1: 0.8804 - val_loss: 0.9825 - val_accuracy: 0.7415 - val_precision_1: 0.7415 - val_recall_1: 0.7415\n",
      "Epoch 19/30\n",
      "78/78 [==============================] - 1s 16ms/step - loss: 0.1992 - accuracy: 0.8753 - precision_1: 0.8753 - recall_1: 0.8753 - val_loss: 0.9896 - val_accuracy: 0.7415 - val_precision_1: 0.7415 - val_recall_1: 0.7415\n",
      "Epoch 20/30\n",
      "78/78 [==============================] - 1s 14ms/step - loss: 0.1973 - accuracy: 0.8846 - precision_1: 0.8846 - recall_1: 0.8846 - val_loss: 0.9959 - val_accuracy: 0.7415 - val_precision_1: 0.7415 - val_recall_1: 0.7415\n",
      "Epoch 21/30\n",
      "78/78 [==============================] - 1s 14ms/step - loss: 0.1995 - accuracy: 0.8822 - precision_1: 0.8822 - recall_1: 0.8822 - val_loss: 0.9854 - val_accuracy: 0.7423 - val_precision_1: 0.7423 - val_recall_1: 0.7423\n",
      "Epoch 22/30\n",
      "78/78 [==============================] - 1s 15ms/step - loss: 0.1952 - accuracy: 0.8794 - precision_1: 0.8794 - recall_1: 0.8794 - val_loss: 1.0067 - val_accuracy: 0.7391 - val_precision_1: 0.7391 - val_recall_1: 0.7391\n",
      "Epoch 23/30\n",
      "78/78 [==============================] - 1s 14ms/step - loss: 0.1980 - accuracy: 0.8828 - precision_1: 0.8828 - recall_1: 0.8828 - val_loss: 0.9959 - val_accuracy: 0.7431 - val_precision_1: 0.7431 - val_recall_1: 0.7431\n",
      "Epoch 24/30\n",
      "78/78 [==============================] - 1s 16ms/step - loss: 0.1970 - accuracy: 0.8769 - precision_1: 0.8769 - recall_1: 0.8769 - val_loss: 0.9870 - val_accuracy: 0.7407 - val_precision_1: 0.7407 - val_recall_1: 0.7407\n",
      "Epoch 25/30\n",
      "78/78 [==============================] - 1s 14ms/step - loss: 0.1956 - accuracy: 0.8790 - precision_1: 0.8790 - recall_1: 0.8790 - val_loss: 0.9872 - val_accuracy: 0.7415 - val_precision_1: 0.7415 - val_recall_1: 0.7415\n",
      "Epoch 26/30\n",
      "78/78 [==============================] - 1s 15ms/step - loss: 0.1935 - accuracy: 0.8826 - precision_1: 0.8826 - recall_1: 0.8826 - val_loss: 0.9805 - val_accuracy: 0.7407 - val_precision_1: 0.7407 - val_recall_1: 0.7407\n",
      "Epoch 27/30\n",
      "22/78 [=======>......................] - ETA: 0s - loss: 0.1992 - accuracy: 0.8913 - precision_1: 0.8913 - recall_1: 0.8913"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_25520/156286642.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m history = model.fit(X_train, y_train,\n\u001b[0m\u001b[0;32m      8\u001b[0m                       \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m                       batch_size=64, epochs=30, verbose=1)\n",
      "\u001b[1;32mE:\\python\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\python\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1214\u001b[0m                 _r=1):\n\u001b[0;32m   1215\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1216\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1217\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1218\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\python\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\python\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    908\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    909\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 910\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    911\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    912\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\python\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    940\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    941\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 942\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    943\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    944\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\python\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3128\u001b[0m       (graph_function,\n\u001b[0;32m   3129\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 3130\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   3131\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   3132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\python\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1957\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1958\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1959\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1960\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1961\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32mE:\\python\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    596\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    597\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 598\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    599\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    600\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\python\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     56\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     59\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     60\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(model.summary())\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer=sgd, \n",
    "               metrics=['accuracy', Precision(), Recall()])\n",
    "\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                      validation_data=(X_test, y_test),\n",
    "                      batch_size=64, epochs=30, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy  : 0.7561\n",
      "Precision : 0.7561\n",
      "Recall    : 0.7561\n",
      "F1 Score  : 0.7561\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy, precision, recall = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('')\n",
    "print('Accuracy  : {:.4f}'.format(accuracy))\n",
    "print('Precision : {:.4f}'.format(precision))\n",
    "print('Recall    : {:.4f}'.format(recall))\n",
    "print('F1 Score  : {:.4f}'.format(f1_score(precision, recall)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model-v4.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "df642eef7b43fe7a4a517bca7a97690968a466268416ac555ac71584a4a4c66c"
  },
  "kernelspec": {
   "display_name": "Python 3.9.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
